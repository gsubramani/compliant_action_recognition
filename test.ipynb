{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guru/Dropbox/lab-hp/workspace/research/end_to_end/end_to_end_env/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\nUsing TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from signal_database.labelSelectedData import SignalDB,SignalBundle,LabeledData\n",
    "from bagfile_io.bagfile_reader import bagfile_reader,write_to_bagfile\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_generator import plotResult_colorbars\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from time_series_learning import label_map,relabel_data,get_signal_features,LSTM_model,SeqGen,load_db,get_wavelet_features\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import load_model\n",
    "import cPickle as pickle\n",
    "from std_msgs.msg import String\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "__doc__ = \"Adds bag files to the database. Used to create training data for detecting compliant actions \"\n",
    "\n",
    "bagfile = \"../some unlabeled data/somepartgrab10.bag\"\n",
    "\n",
    "\n",
    "label_names_df = pickle.load(open(\"label_names_df.pkl\", \"rb\"))\n",
    "\n",
    "bfr = bagfile_reader(bagfile)\n",
    "\n",
    "\n",
    "\n",
    "wrench1_,wrencht1 = bfr.get_topic_msgs(\"/ftmini40\")\n",
    "wrench2_,wrencht2 = bfr.get_topic_msgs(\"/ftmini402\")\n",
    "labels_,labelst = bfr.get_topic_msgs(\"/labels\")\n",
    "\n",
    "timesamples = list(wrencht1)\n",
    "\n",
    "# labels = [label_messsage.data for label_messsage in labels_]\n",
    "\n",
    "wrench1 = np.array([[f.wrench.force.x,f.wrench.force.y,f.wrench.force.z,\n",
    "                f.wrench.torque.x,f.wrench.torque.y,f.wrench.torque.z] for f in wrench1_])\n",
    "\n",
    "wrench2 = np.array([[f.wrench.force.x,f.wrench.force.y,f.wrench.force.z,\n",
    "                f.wrench.torque.x,f.wrench.torque.y,f.wrench.torque.z] for f in wrench2_])\n",
    "\n",
    "\n",
    "wrench1 = np.array([np.interp(timesamples,  wrencht1, wrench1[:,ii]) for ii in range(6)]).transpose()\n",
    "wrench2 = np.array([np.interp(timesamples,  wrencht2, wrench2[:,ii]) for ii in range(6)]).transpose()\n",
    "\n",
    "\n",
    "data = np.transpose(np.append(wrench1,wrench2,axis = 1)).tolist()\n",
    "\n",
    "#addings stuff to the database\n",
    "sb = SignalBundle(data,timesamples)\n",
    "ld = LabeledData(sb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# labels = [label_str.data for label_str in labels_]\n",
    "# \n",
    "# \n",
    "# if len(labels) == 0:\n",
    "#     labels = np.shape(wrench1)[0]*['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ld.labels = labels\n",
    "data = [ld]\n",
    "timestamps = np.array(ld.signal_bundle.timestamps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38076, 4) (38076,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38076, 80)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_signal,Y = get_signal_features(data)\n",
    "X_wavelet, _ = get_wavelet_features(data)\n",
    "print np.shape(X_wavelet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381, 80) (38076, 4) (38076,)\n"
     ]
    }
   ],
   "source": [
    "print np.shape(X_wavelet),np.shape(X_signal),np.shape(data[0].signal_bundle.signals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38076, 4) (381,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = np.append(X_signal,X_wavelet,axis = 1)\n",
    "#X = X_signal\n",
    "# model_LSTM_saved = load_model(\"./trained_models/LSTM_only.hdf5\")\n",
    "model_LSTM_saved = load_model(\"./trained_models/LSTM_wavelet_10ep.hdf5\")\n",
    "\n",
    "\n",
    "window = 100\n",
    "batch_stride = 1\n",
    "batch_size = 1\n",
    "num_classes = len(label_names_df)\n",
    "data_dim = np.shape(X)[1]\n",
    "\n",
    "model_LSTM = LSTM_model(data_dim, window, batch_size, num_classes, stateful=False)\n",
    "\n",
    "model_LSTM.set_weights(model_LSTM_saved.get_weights())\n",
    "\n",
    "skip = 100\n",
    "\n",
    "Y_one_hot = pd.get_dummies(Y,columns=list(label_names_df))\n",
    "sg = SeqGen(X[0:-1:skip],Y_one_hot[0:-1:skip],1,window,batch_stride=1)\n",
    "sg_timesamples = SeqGen(X[0:-1:skip],timesamples[0:-1:skip],1,window,batch_stride=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8)\n['freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'grab', 'grab', 'grab', 'grab', 'grab', 'freespace', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', '', 'release', 'release', 'release', 'release', 'release', 'release', 'release', 'release', 'release', 'release', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', '', '', '', '', '', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', '', '', '', '', '', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = np.array([]).reshape(0,len(label_names_df))\n",
    "timesamples_predict = []\n",
    "\n",
    "for ii in range(len(sg)):\n",
    "    predictions = np.append(model_LSTM.predict(sg[ii][0],batch_size=batch_size),predictions,axis = 0)\n",
    "    timesamples_predict = sg_timesamples[ii][1].tolist() + timesamples_predict\n",
    "\n",
    "print np.shape(sg[ii][1])\n",
    "\n",
    "predict_df = pd.DataFrame(predictions, columns=label_names_df)\n",
    "predict_list = list(predict_df.idxmax(axis=1))\n",
    "\n",
    "\n",
    "\n",
    "print predict_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6a97484310>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(timesamples_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timesamples_predict_zeroed' is not defined",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6b191dbe4f93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesamples_predict_zeroed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'timesamples_predict_zeroed' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# plt.plot(timesamples_predict_zeroed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', 'hand_on', '', '', '', '', '', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'grab', 'grab', 'grab', 'grab', 'grab', 'freespace', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', 'grab', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', 'hold', '', 'release', 'release', 'release', 'release', 'release', 'release', 'release', 'release', 'release', 'release', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'freespace', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'hand_off', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', 'still', '', '', '', '', '', 'still']\n"
     ]
    }
   ],
   "source": [
    "indices = np.argsort(timesamples_predict)\n",
    "timesamples_predict_ = np.sort(timesamples_predict)\n",
    "indices =  np.argsort(timesamples_predict)\n",
    "predict_list_sorted = [predict_list[indice] for indice in indices]\n",
    "print predict_list_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(timesamples_predict)\n",
    "timesamples_predict_ = np.sort(timesamples_predict)\n",
    "\n",
    "test_one_hot_predict_series_ = [predict_list[indice] for indice in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_one_hot_predict_series_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6ab0056790>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_one_hot_predict_series = []\n",
    "test_one_hot_truth_series = []\n",
    "\n",
    "\n",
    "for ii in range(len(sg)):\n",
    "    test_one_hot_predict = model_LSTM.predict(sg[ii][0], batch_size=batch_size)\n",
    "    test_one_hot_predict_df = pd.DataFrame(test_one_hot_predict, columns=label_names_df)\n",
    "    test_one_hot_predict_series_batch = list(test_one_hot_predict_df.idxmax(axis=1))\n",
    "    test_one_hot_predict_series = test_one_hot_predict_series + test_one_hot_predict_series_batch\n",
    "\n",
    "    # test_one_hot_truth = (sg[ii][1] > 0.9).astype(int)\n",
    "    # print np.shape(test_one_hot_truth)\n",
    "    # test_one_hot_truth_df = pd.DataFrame(test_one_hot_truth, columns=label_names_df)\n",
    "    # test_one_hot_truth_series_batch = list(test_one_hot_truth_df.idxmax(axis=1))\n",
    "    # test_one_hot_truth_series = test_one_hot_truth_series + test_one_hot_truth_series_batch\n",
    "\n",
    "plt.figure(1)\n",
    "ax = plt.subplot(2, 1, 1)\n",
    "\n",
    "plotResult_colorbars(test_one_hot_predict_series_, range(len(test_one_hot_predict_series_)),\n",
    "                     labelNames=list(label_names_df) + [''], ax=ax, medfiltwidth=1)\n",
    "# ax.set_xlim([min(timesamples_predict), max(timesamples_predict)])\n",
    "# ax = plt.subplot(2, 1, 2)\n",
    "# \n",
    "# plotResult_colorbars(test_one_hot_truth_series, timesamples_predict,\n",
    "#                      labelNames=list(label_names_df) + [''], medfiltwidth=1)\n",
    "# ax.set_xlim([0, len(test_one_hot_truth_series)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a99884b10>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_labels = np.array(pd.DataFrame(data = test_one_hot_predict_series_))\n",
    "out_labels = np.repeat(out_labels,100)\n",
    "timesamples_predict_interp = np.linspace(min(timesamples_predict_), max(timesamples_predict_),num = len(out_labels))\n",
    "plt.figure(1)\n",
    "ax = plt.subplot(2, 1, 1)\n",
    "plotResult_colorbars(out_labels.tolist(), range(len(out_labels)),\n",
    "                     labelNames=list(label_names_df) + [''], ax=ax, medfiltwidth=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6a9baa3cd0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(timesamples_predict_interp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rospy\n",
    "\n",
    "# labels_t = [rospy.Time.from_sec(sec) for sec in timesamples_predict_interp]\n",
    "labels_t = timesamples_predict_interp.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6a9b7d1e90>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(labels_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hold'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "string_message_list = []\n",
    "\n",
    "for label in predict_list_sorted:\n",
    "    message = String()\n",
    "    message.data = label\n",
    "    string_message_list.append(message)\n",
    "\n",
    "bigger_string_message_list = []\n",
    "\n",
    "for message in string_message_list:\n",
    "    bigger_string_message_list = bigger_string_message_list + [message]*100    \n",
    "\n",
    "\n",
    "write_to_bagfile(bagfile, '/labels11',bigger_string_message_list, labels_t, 'a', createbackup=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rosbag\n",
    "topicname = '/labels8'\n",
    "with rosbag.Bag(bagfile, 'a') as bag:\n",
    "    for msg,stamp in zip(string_message_list,labels_t):\n",
    "        bag.write(topicname, msg, rospy.Time.from_sec(stamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfr = bagfile_reader(bagfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1525906423.6802917"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rospy.Time.from_sec(labels_t[-1]).to_sec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,timestamps_check = bfr.get_topic_msgs('/labels8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1525906423.68 1525906423.6802917\n"
     ]
    }
   ],
   "source": [
    "print labels_t[-1],timestamps_check[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "381"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(string_message_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
